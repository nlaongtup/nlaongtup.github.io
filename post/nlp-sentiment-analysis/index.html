<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.5.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Nuttapong La-ongtup">

  
  
  
    
  
  <meta name="description" content="Using Transformer, PyTorch and Scikit-Learn">

  
  <link rel="alternate" hreflang="en-us" href="https://nlaongtup.github.io/post/nlp-sentiment-analysis/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.3b22c150b33731e873cb2255c65de711.css">

  

  
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://nlaongtup.github.io/post/nlp-sentiment-analysis/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Nuttapong La-ongtup">
  <meta property="og:url" content="https://nlaongtup.github.io/post/nlp-sentiment-analysis/">
  <meta property="og:title" content="Explore three difference NLP models for Sentiment Analysis: Logistic Regression, LSTM and BERT | Nuttapong La-ongtup">
  <meta property="og:description" content="Using Transformer, PyTorch and Scikit-Learn"><meta property="og:image" content="https://nlaongtup.github.io/post/nlp-sentiment-analysis/featured.png">
  <meta property="twitter:image" content="https://nlaongtup.github.io/post/nlp-sentiment-analysis/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2022-09-04T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2022-09-04T00:00:00&#43;00:00">
  

  


    






  





  





  





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nlaongtup.github.io/post/nlp-sentiment-analysis/"
  },
  "headline": "Explore three difference NLP models for Sentiment Analysis: Logistic Regression, LSTM and BERT",
  
  "image": [
    "https://nlaongtup.github.io/post/nlp-sentiment-analysis/featured.png"
  ],
  
  "datePublished": "2022-09-04T00:00:00Z",
  "dateModified": "2022-09-04T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Nuttapong La-ongtup"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Nuttapong La-ongtup",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nlaongtup.github.io/img/icon-512.png"
    }
  },
  "description": "Using Transformer, PyTorch and Scikit-Learn"
}
</script>

  

  


  


  





  <title>Explore three difference NLP models for Sentiment Analysis: Logistic Regression, LSTM and BERT | Nuttapong La-ongtup</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Nuttapong La-ongtup</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/cv.pdf"><span>CV</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Explore three difference NLP models for Sentiment Analysis: Logistic Regression, LSTM and BERT</h1>

  

  



<div class="article-metadata">

  
  
  
  
  <div>
    



  <span><a href="/authors/admin/">Nuttapong La-ongtup</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Sep 4, 2022
  </span>
  

  

  

  
  
  

  
  

  
    

  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 480px;">
  <div style="position: relative">
    <img src="/post/nlp-sentiment-analysis/featured_hu3d03a01dcc18bc5be0e67db3d8d209a6_1592635_720x0_resize_lanczos_3.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>Sentiment Analysis can be useful for businesses to help understand sentiment in customer feedback or review for better understanding and improvement on the products efficiently. We are going to explore three different NLP models for Sentiment Analysis.</p>
<h3 id="three-models-at-a-glance">Three Models at a Glance</h3>
<ol>
<li><strong>Logistic Regression</strong>: A well known simple statistical model that use logistic function to represent probability of an occurrence.</li>
</ol>
<p><img src="./logistic-curve.svg" alt="svg" title="The standard logistic function or a sigmoid"></p>
<ol start="2">
<li><strong>LSTM</strong>: Long Short-Term Memory (LSTM) developed to solve the memory lost problem of RNN on long sequence of data by providing a short-term memory for RNN that last a lot more, hence, it called <strong>&ldquo;long&rdquo;</strong> short-term memory.</li>
</ol>
<p><img src="./rnn_lstm.png" alt="png" title="RNN vs LSTM"></p>
<ol start="3">
<li><strong>BERT</strong>: Bidirectional Encoder Representations from Transformers (BERT) developed by research team at Google. They fixed the shortage of training data problem, enable a training process to enormous amount of unannotated text plain text corpus like Wikipedia. Introducing <strong>&ldquo;self-attention&rdquo;</strong> technique, masking out some of the words in the input and predict the masked words and let the predictor use entire context make it truly efficient bidirectional training schema.</li>
</ol>
<p><img src="./bert_fine-tuning.png" alt="png" title="Overall pre-training and fine-tuning procedures for BERT"></p>
<p>For full details about BERT model, refer to this publication: <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
<p><strong>Note:</strong> The full codes in this article are in <strong>Google Colab</strong></p>
<ul>
<li><a href="https://colab.research.google.com/drive/12n5hppqsJXHo6m3XptR8sz40iaAFnaNS?usp=sharing">Sentiment_Analysis_BERT.ipynb</a></li>
<li><a href="https://colab.research.google.com/drive/1wQ49e_rx_pZjkbG2I6roR5lWMeRW9Avk?usp=sharing">Sentiment_Analysis_LSTM.ipynb</a></li>
<li><a href="https://colab.research.google.com/drive/1gX56DN9NQMFfF5nFZdQbwAmijN1TjyFf?usp=sharing">Sentiment_Analysis_Logistic_Regression.ipynb</a></li>
</ul>
<h3 id="1-logistic-regression-model-with-tf-idf">1. Logistic Regression Model with TF-IDF</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> TfidfVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> load_dataset(<span style="color:#e6db74">&#34;yelp_review_full&#34;</span>)
</span></span><span style="display:flex;"><span>train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset[<span style="color:#e6db74">&#34;train&#34;</span>])
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset[<span style="color:#e6db74">&#34;test&#34;</span>])
</span></span><span style="display:flex;"><span>sample_frac <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0025</span>
</span></span><span style="display:flex;"><span>train <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>sample(frac<span style="color:#f92672">=</span>sample_frac)
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>sample(frac<span style="color:#f92672">=</span>sample_frac)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocessor</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;&lt;[^&gt;]*&gt;&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>    emoticons <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>findall(<span style="color:#e6db74">&#39;(?::|;|=)(?:-)?(?:\)|\(|D|P)&#39;</span>, text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> (re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;[\W]+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>,
</span></span><span style="display:flex;"><span>            text<span style="color:#f92672">.</span>lower()) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(emoticons)<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;-&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>porter <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenizer_porter</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [porter<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> text<span style="color:#f92672">.</span>split()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> train[<span style="color:#e6db74">&#39;text&#39;</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> train[<span style="color:#e6db74">&#39;label&#39;</span>]
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X,
</span></span><span style="display:flex;"><span>                                                    y,
</span></span><span style="display:flex;"><span>                                                    random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                                                    stratify<span style="color:#f92672">=</span>y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tfidf <span style="color:#f92672">=</span> TfidfVectorizer(strip_accents<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                        lowercase<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                        stop_words<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                        tokenizer<span style="color:#f92672">=</span>tokenizer_porter
</span></span><span style="display:flex;"><span>                        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lr_tfidf <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;vect&#39;</span>, tfidf),
</span></span><span style="display:flex;"><span>                     (<span style="color:#e6db74">&#39;clf&#39;</span>, LogisticRegression(multi_class<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;multinomial&#39;</span>,
</span></span><span style="display:flex;"><span>                                                random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lr_tfidf<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test <span style="color:#f92672">=</span> test[<span style="color:#e6db74">&#39;text&#39;</span>]
</span></span><span style="display:flex;"><span>y_test <span style="color:#f92672">=</span> test[<span style="color:#e6db74">&#39;label&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict_text</span>(text):
</span></span><span style="display:flex;"><span>    preds_label <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> preds_label
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pred_label <span style="color:#f92672">=</span> predict_text(test[<span style="color:#e6db74">&#39;text&#39;</span>])
</span></span><span style="display:flex;"><span>pred_label_list <span style="color:#f92672">=</span> list(pred_label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>reset_index(drop<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>test_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(test[<span style="color:#e6db74">&#34;label&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>compared_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([test, pred_test_df],axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>model1_pred <span style="color:#f92672">=</span> compared_df
</span></span><span style="display:flex;"><span>model1_pred<span style="color:#f92672">.</span>head()
</span></span><span style="display:flex;"><span>confusion_matrix <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>crosstab(model1_pred<span style="color:#f92672">.</span>pred_label,model1_pred<span style="color:#f92672">.</span>label)
</span></span><span style="display:flex;"><span>confusion_matrix
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>ax1 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>heatmap(confusion_matrix, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Blues&#39;</span>, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;g&#39;</span>, vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
</span></span></code></pre></div><p><img src="./confusion_metrix_logistic_regression.png" alt="png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>classification_report(compared_df[<span style="color:#e6db74">&#34;label&#34;</span>], compared_df[<span style="color:#e6db74">&#34;pred_label&#34;</span>])
</span></span></code></pre></div><pre><code>          precision    recall  f1-score   support

       0       0.59      0.64      0.62        25
       1       0.42      0.43      0.43        23
       2       0.43      0.40      0.42        25
       3       0.50      0.37      0.42        30
       4       0.45      0.59      0.51        22

accuracy                           0.48       125
macro avg      0.48      0.49      0.48       125
weighted avg   0.48      0.48      0.48       125
</code></pre>
<h3 id="2-lstm-model">2. LSTM Model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> spacy
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> copy
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> preprocessing
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> Counter
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> TensorDataset, DataLoader
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> string
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> load_dataset(<span style="color:#e6db74">&#34;yelp_review_full&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset[<span style="color:#e6db74">&#34;train&#34;</span>])
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset[<span style="color:#e6db74">&#34;test&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>sample(frac<span style="color:#f92672">=</span><span style="color:#ae81ff">0.025</span>)
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>sample(frac<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>reviews[<span style="color:#e6db74">&#39;length&#39;</span>] <span style="color:#f92672">=</span> reviews[<span style="color:#e6db74">&#39;text&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: len(x<span style="color:#f92672">.</span>split()))
</span></span><span style="display:flex;"><span>mean_length <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(reviews[<span style="color:#e6db74">&#39;length&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess_string</span>(s):
</span></span><span style="display:flex;"><span>    s <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;\s+&#34;</span>, <span style="color:#e6db74">&#39;&#39;</span>, s)
</span></span><span style="display:flex;"><span>    s <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;\d&#34;</span>, <span style="color:#e6db74">&#39;&#39;</span>, s)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tok <span style="color:#f92672">=</span> spacy<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;en_core_web_sm&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenize</span> (text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;[^\x00-\x7F]+&#34;</span>, <span style="color:#e6db74">&#34; &#34;</span>, text)
</span></span><span style="display:flex;"><span>    regex <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">&#39;[&#39;</span> <span style="color:#f92672">+</span> re<span style="color:#f92672">.</span>escape(string<span style="color:#f92672">.</span>punctuation) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;0-9</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">r</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">t</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">n]&#39;</span>) <span style="color:#75715e"># remove punctuation and numbers</span>
</span></span><span style="display:flex;"><span>    nopunct <span style="color:#f92672">=</span> regex<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#34; &#34;</span>, text<span style="color:#f92672">.</span>lower())
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [token<span style="color:#f92672">.</span>text <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tok<span style="color:#f92672">.</span>tokenizer(nopunct)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>porter <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenizer_porter</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [porter<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> text<span style="color:#f92672">.</span>split()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>counts <span style="color:#f92672">=</span> Counter()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> index, row <span style="color:#f92672">in</span> reviews<span style="color:#f92672">.</span>iterrows():
</span></span><span style="display:flex;"><span>    counts<span style="color:#f92672">.</span>update(tokenize(row[<span style="color:#e6db74">&#39;text&#39;</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> list(counts):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> counts[word] <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">2</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">del</span> counts[word]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vocab2index <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#34;&#34;</span>:<span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;UNK&#34;</span>:<span style="color:#ae81ff">1</span>}
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;UNK&#34;</span>]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> counts:
</span></span><span style="display:flex;"><span>    vocab2index[word] <span style="color:#f92672">=</span> len(words)
</span></span><span style="display:flex;"><span>    words<span style="color:#f92672">.</span>append(word)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vocab_size <span style="color:#f92672">=</span> len(words)
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> train[<span style="color:#e6db74">&#39;text&#39;</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> train[<span style="color:#e6db74">&#39;label&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train,X_eval,y_train,y_eval <span style="color:#f92672">=</span> train_test_split(X,y,stratify<span style="color:#f92672">=</span>y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tockenize</span>(x_train,y_train,x_eval,y_eval):
</span></span><span style="display:flex;"><span>    final_list_train,final_list_test <span style="color:#f92672">=</span> [],[]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> sent <span style="color:#f92672">in</span> x_train:
</span></span><span style="display:flex;"><span>      tokenized <span style="color:#f92672">=</span> tokenize(sent)
</span></span><span style="display:flex;"><span>      encoded <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">170</span>, dtype<span style="color:#f92672">=</span>int)
</span></span><span style="display:flex;"><span>      enc1 <span style="color:#f92672">=</span> [vocab2index<span style="color:#f92672">.</span>get(word, vocab2index[<span style="color:#e6db74">&#34;UNK&#34;</span>]) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized]
</span></span><span style="display:flex;"><span>      final_list_train<span style="color:#f92672">.</span>append(enc1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> sent <span style="color:#f92672">in</span> x_eval:
</span></span><span style="display:flex;"><span>      tokenized <span style="color:#f92672">=</span> tokenize(sent)
</span></span><span style="display:flex;"><span>      encoded <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">170</span>, dtype<span style="color:#f92672">=</span>int)
</span></span><span style="display:flex;"><span>      enc1 <span style="color:#f92672">=</span> [vocab2index<span style="color:#f92672">.</span>get(word, vocab2index[<span style="color:#e6db74">&#34;UNK&#34;</span>]) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized]
</span></span><span style="display:flex;"><span>      final_list_test<span style="color:#f92672">.</span>append(enc1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    encoded_train <span style="color:#f92672">=</span> y_train
</span></span><span style="display:flex;"><span>    encoded_test <span style="color:#f92672">=</span> y_eval
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(final_list_train, dtype<span style="color:#f92672">=</span>object), encoded_train,np<span style="color:#f92672">.</span>array(final_list_test, dtype<span style="color:#f92672">=</span>object), encoded_test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x_train,y_train,x_eval,y_eval <span style="color:#f92672">=</span> tockenize(X_train,y_train,X_eval,y_eval)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">padding_</span>(sentences, seq_len):
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((len(sentences), seq_len),dtype<span style="color:#f92672">=</span>int)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> ii, review <span style="color:#f92672">in</span> enumerate(sentences):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(review) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#34;np.array(review)=&#34;, np.array(review))</span>
</span></span><span style="display:flex;"><span>            features[ii, <span style="color:#f92672">-</span>len(review):] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(review)[:seq_len]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> features
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x_train_pad <span style="color:#f92672">=</span> padding_(x_train,<span style="color:#ae81ff">160</span>)
</span></span><span style="display:flex;"><span>x_eval_pad <span style="color:#f92672">=</span> padding_(x_eval,<span style="color:#ae81ff">160</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_data <span style="color:#f92672">=</span> TensorDataset(torch<span style="color:#f92672">.</span>from_numpy(x_train_pad), torch<span style="color:#f92672">.</span>from_numpy(np<span style="color:#f92672">.</span>asarray(y_train)))
</span></span><span style="display:flex;"><span>valid_data <span style="color:#f92672">=</span> TensorDataset(torch<span style="color:#f92672">.</span>from_numpy(x_eval_pad), torch<span style="color:#f92672">.</span>from_numpy(np<span style="color:#f92672">.</span>asarray(y_eval)))
</span></span><span style="display:flex;"><span>batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>train_loader <span style="color:#f92672">=</span> DataLoader(train_data, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, batch_size<span style="color:#f92672">=</span>batch_size, drop_last<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>valid_loader <span style="color:#f92672">=</span> DataLoader(valid_data, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, batch_size<span style="color:#f92672">=</span>batch_size, drop_last<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataiter <span style="color:#f92672">=</span> iter(train_loader)
</span></span><span style="display:flex;"><span>sample_x, sample_y <span style="color:#f92672">=</span> dataiter<span style="color:#f92672">.</span>next()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>is_cuda <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If we have a GPU available, we&#39;ll set our device to GPU. We&#39;ll use this device variable later in our code.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> is_cuda:
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cpu&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>    dataiter <span style="color:#f92672">=</span> iter(train_loader)
</span></span><span style="display:flex;"><span>    sample_x, sample_y <span style="color:#f92672">=</span> next(dataiter)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>    dataiter <span style="color:#f92672">=</span> iter(train_loader)
</span></span><span style="display:flex;"><span>    sample_x, sample_y <span style="color:#f92672">=</span> dataiter<span style="color:#f92672">.</span>next()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SentimentAnalysis</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module) :
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, vocab_size, embedding_dim, hidden_dim, dropout) :
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedding <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(vocab_size, embedding_dim, padding_idx<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTM(embedding_dim, hidden_dim, batch_first<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dropout <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Dropout(dropout)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(hidden_dim, <span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>hidden_dim <span style="color:#f92672">=</span> hidden_dim
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, hidden):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        The forward method takes in the input and the previous hidden state
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        embs <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embedding(x)
</span></span><span style="display:flex;"><span>        out, hidden <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(embs, hidden)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> out[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out, hidden
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">init_hidden</span>(self, batch_size):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">1</span>, batch_size, self<span style="color:#f92672">.</span>hidden_dim), torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">1</span>, batch_size, self<span style="color:#f92672">.</span>hidden_dim))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SentimentAnalysis(vocab_size, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">0.25</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>losses <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>valid_acc_min <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>Inf
</span></span><span style="display:flex;"><span>best_model_wts <span style="color:#f92672">=</span> copy<span style="color:#f92672">.</span>deepcopy(model<span style="color:#f92672">.</span>state_dict())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> e <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>    h0, c0 <span style="color:#f92672">=</span>  model<span style="color:#f92672">.</span>init_hidden(batch_size)
</span></span><span style="display:flex;"><span>    h0 <span style="color:#f92672">=</span> h0<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>    c0 <span style="color:#f92672">=</span> c0<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> batch_idx, batch <span style="color:#f92672">in</span> enumerate(train_loader):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        input <span style="color:#f92672">=</span> batch[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>type(torch<span style="color:#f92672">.</span>LongTensor)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>        target <span style="color:#f92672">=</span> batch[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>type(torch<span style="color:#f92672">.</span>LongTensor)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>set_grad_enabled(<span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>            out, hidden <span style="color:#f92672">=</span> model(input, (h0, c0))
</span></span><span style="display:flex;"><span>            loss <span style="color:#f92672">=</span> criterion(out, target)
</span></span><span style="display:flex;"><span>            loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>    losses<span style="color:#f92672">.</span>append(loss<span style="color:#f92672">.</span>item())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>    batch_acc <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> batch_idx, batch <span style="color:#f92672">in</span> enumerate(valid_loader):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        input <span style="color:#f92672">=</span> batch[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>        target <span style="color:#f92672">=</span> batch[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>set_grad_enabled(<span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>            out, hidden <span style="color:#f92672">=</span> model(input, (h0, c0))
</span></span><span style="display:flex;"><span>            _, preds <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(out, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            preds <span style="color:#f92672">=</span> preds<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cpu&#34;</span>)<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>            batch_acc <span style="color:#f92672">=</span> accuracy_score(preds, target<span style="color:#f92672">.</span>tolist())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;epoch:&#34;</span>, e<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#34;eval_acc:&#34;</span>, batch_acc)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> batch_acc <span style="color:#f92672">&gt;=</span> valid_acc_min:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;saving model ...&#39;</span>)
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>save(model<span style="color:#f92672">.</span>state_dict(), <span style="color:#e6db74">&#39;./sentiment.pt&#39;</span>)
</span></span><span style="display:flex;"><span>        best_model_wts <span style="color:#f92672">=</span> copy<span style="color:#f92672">.</span>deepcopy(model<span style="color:#f92672">.</span>state_dict())
</span></span><span style="display:flex;"><span>        valid_acc_min <span style="color:#f92672">=</span> batch_acc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>load_state_dict(best_model_wts)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict_text</span>(text):
</span></span><span style="display:flex;"><span>    tokenized <span style="color:#f92672">=</span> tokenize(text)
</span></span><span style="display:flex;"><span>    encoded <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">170</span>, dtype<span style="color:#f92672">=</span>int)
</span></span><span style="display:flex;"><span>    token_list <span style="color:#f92672">=</span> [vocab2index<span style="color:#f92672">.</span>get(word, vocab2index[<span style="color:#e6db74">&#34;UNK&#34;</span>]) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized]
</span></span><span style="display:flex;"><span>    token_list_pad <span style="color:#f92672">=</span> padding_([token_list], <span style="color:#ae81ff">170</span>)
</span></span><span style="display:flex;"><span>    pad <span style="color:#f92672">=</span>  torch<span style="color:#f92672">.</span>from_numpy(token_list_pad)
</span></span><span style="display:flex;"><span>    inputs <span style="color:#f92672">=</span> pad<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    h0, c0 <span style="color:#f92672">=</span>  model<span style="color:#f92672">.</span>init_hidden(batch_size)
</span></span><span style="display:flex;"><span>    h0 <span style="color:#f92672">=</span> h0<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>    c0 <span style="color:#f92672">=</span> c0<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>    outputs, h <span style="color:#f92672">=</span> model(inputs, (h0, c0))
</span></span><span style="display:flex;"><span>    _, preds <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(outputs, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    preds <span style="color:#f92672">=</span> preds<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cpu&#34;</span>)<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>    score <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(outputs , dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>tolist()[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    label <span style="color:#f92672">=</span> str(label_encoder<span style="color:#f92672">.</span>inverse_transform(preds)[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> label,score[preds[<span style="color:#ae81ff">0</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>reset_index(drop<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    pred_label_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test[<span style="color:#e6db74">&#39;text&#39;</span>]:
</span></span><span style="display:flex;"><span>    pred_label <span style="color:#f92672">=</span> predict_text(text)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    pred_label_list<span style="color:#f92672">.</span>append(pred_label)
</span></span><span style="display:flex;"><span>pred_test_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(pred_label_list, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;pred_label&#39;</span>])
</span></span><span style="display:flex;"><span>test_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(test[<span style="color:#e6db74">&#34;label&#34;</span>])
</span></span><span style="display:flex;"><span>compared_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([test, pred_test_df],axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model2_pred <span style="color:#f92672">=</span> compared_df
</span></span><span style="display:flex;"><span>confusion_matrix <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>crosstab(model2_pred<span style="color:#f92672">.</span>pred_label,model1_pred<span style="color:#f92672">.</span>label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>ax1 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>heatmap(confusion_matrix, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Blues&#39;</span>, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;g&#39;</span>, vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">700</span>)
</span></span></code></pre></div><p><img src="./confusion_metrix_lstm.png" alt="png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>classification_report(compared_df[<span style="color:#e6db74">&#34;label&#34;</span>], compared_df[<span style="color:#e6db74">&#34;pred_label&#34;</span>])
</span></span></code></pre></div><pre><code>          precision    recall  f1-score   support

       0       0.69      0.72      0.71      2442
       1       0.51      0.46      0.49      2522
       2       0.48      0.53      0.50      2520
       3       0.48      0.49      0.48      2502
       4       0.68      0.63      0.66      2514

accuracy                           0.56     12500
macro avg      0.57     0.57       0.57     12500
weighted avg   0.57     0.56       0.57     12500
</code></pre>
<h3 id="3-bert-model">3. BERT model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoTokenizer, DataCollatorWithPadding
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoModelForSequenceClassification
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> TrainingArguments
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> TrainingArguments, Trainer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_metric, load_dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> load_dataset(<span style="color:#e6db74">&#34;yelp_review_full&#34;</span>)
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;bert-base-cased&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenize_function</span>(examples):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tokenizer(examples[<span style="color:#e6db74">&#34;text&#34;</span>], padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;max_length&#34;</span>, truncation<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_datasets <span style="color:#f92672">=</span> dataset<span style="color:#f92672">.</span>map(tokenize_function, batched<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sample_frac <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0025</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>small_train_dataset <span style="color:#f92672">=</span> tokenized_datasets[<span style="color:#e6db74">&#34;train&#34;</span>]<span style="color:#f92672">.</span>shuffle(seed<span style="color:#f92672">=</span><span style="color:#ae81ff">777</span>)<span style="color:#f92672">.</span>select(range(int(<span style="color:#ae81ff">650000</span><span style="color:#f92672">*</span>sample_frac)))
</span></span><span style="display:flex;"><span>small_eval_dataset <span style="color:#f92672">=</span> tokenized_datasets[<span style="color:#e6db74">&#34;train&#34;</span>]<span style="color:#f92672">.</span>shuffle(seed<span style="color:#f92672">=</span><span style="color:#ae81ff">777</span>)<span style="color:#f92672">.</span>select(range(<span style="color:#ae81ff">650000</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">650000</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>int(<span style="color:#ae81ff">650000</span><span style="color:#f92672">*</span>sample_frac), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> AutoModelForSequenceClassification<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;bert-base-cased&#34;</span>, num_labels<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> TrainingArguments(output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;test_trainer&#34;</span>)
</span></span><span style="display:flex;"><span>metric <span style="color:#f92672">=</span> load_metric(<span style="color:#e6db74">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_metrics</span>(eval_pred):
</span></span><span style="display:flex;"><span>    logits, labels <span style="color:#f92672">=</span> eval_pred
</span></span><span style="display:flex;"><span>    predictions <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(logits, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> metric<span style="color:#f92672">.</span>compute(predictions<span style="color:#f92672">=</span>predictions, references<span style="color:#f92672">=</span>labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;test_trainer&#34;</span>,
</span></span><span style="display:flex;"><span>num_train_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>eval_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">125</span>,
</span></span><span style="display:flex;"><span>logging_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">125</span>,
</span></span><span style="display:flex;"><span>evaluation_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;epoch&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>small_train_dataset,
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>small_eval_dataset,
</span></span><span style="display:flex;"><span>    compute_metrics<span style="color:#f92672">=</span>compute_metrics,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_metrics</span>(eval_pred):
</span></span><span style="display:flex;"><span>    logits, labels <span style="color:#f92672">=</span> eval_pred
</span></span><span style="display:flex;"><span>    predictions <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(logits, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> metric<span style="color:#f92672">.</span>compute(predictions<span style="color:#f92672">=</span>predictions, references<span style="color:#f92672">=</span>labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cuda&#39;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset[<span style="color:#e6db74">&#34;test&#34;</span>])
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>sample(frac<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>reset_index(drop<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>test_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(test[<span style="color:#e6db74">&#34;label&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict_text</span>(text):
</span></span><span style="display:flex;"><span>  input_token <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>encode(text, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pt&#39;</span>)
</span></span><span style="display:flex;"><span>  input_token <span style="color:#f92672">=</span> input_token<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>  pred_result <span style="color:#f92672">=</span> model(input_token)
</span></span><span style="display:flex;"><span>  pred_label <span style="color:#f92672">=</span> int(torch<span style="color:#f92672">.</span>argmax(pred_result<span style="color:#f92672">.</span>logits))
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> pred_label
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>compared_df <span style="color:#f92672">=</span> test
</span></span><span style="display:flex;"><span>compared_df[<span style="color:#e6db74">&#34;pred_label&#34;</span>] <span style="color:#f92672">=</span> compared_df[<span style="color:#e6db74">&#34;text&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: predict_text(x[:<span style="color:#ae81ff">512</span>]))
</span></span><span style="display:flex;"><span>model3_pred <span style="color:#f92672">=</span> compared_df
</span></span><span style="display:flex;"><span>confusion_matrix <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>crosstab(model1_pred<span style="color:#f92672">.</span>pred_label,model1_pred<span style="color:#f92672">.</span>label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>ax1 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>heatmap(confusion_matrix, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Blues&#39;</span>, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;g&#39;</span>, vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">700</span>)
</span></span></code></pre></div><p><img src="./confusion_metrix_BERT.png" alt="png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>classification_report(compared_df[<span style="color:#e6db74">&#34;label&#34;</span>], compared_df[<span style="color:#e6db74">&#34;pred_label&#34;</span>])
</span></span></code></pre></div><pre><code>          precision    recall  f1-score   support

       0       0.74      0.51      0.61      1015
       1       0.45      0.51      0.48      1018
       2       0.41      0.46      0.44      1004
       3       0.44      0.53      0.48      1012
       4       0.63      0.54      0.58       951

accuracy                           0.51      5000
macro avg     0.54      0.51       0.52      5000
weighted avg  0.53      0.51       0.52      5000
</code></pre>
<h3 id="final-thought">Final thought</h3>
<p>The results are not so different from each model. Its good to try a simple model first as a baseline and then to use a more complex model which required a lot of computational resources. Anyway, the Text Classification task is a good way to start learning NLP. Im glad Ive explored them. </p>
<p>Next time I will try the famous Thai language NLP lib called <strong><em>PyThaiNLP</em></strong> for tokenizing, fine-tuning Thai language pre-trained BERT model <strong><em>WangchanBERTa</em></strong>, and utilizing Thai datasets like Wisesight Sentiment corpus. Its gonna be even more fun! </p>
<pre tabindex="0"><code></code></pre>
    </div>

    


    



    
      








  
  
    
  
  






  
  
  
    
  
  
  <div class="media author-card">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu6731755d363b532d82bb1744ccd619ab_290514_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://nlaongtup.github.io/">Nuttapong La-ongtup</a></h5>
      
      <p class="card-text">If I have seen further it is by standing on the shoulders of Giants - Isaac Newton</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
          <li>
            <a href="mailto:nuttapong-laongtup@uacj.co.jp" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://www.linkedin.com/in/nuttapong-la-ongtup-444345140/" target="_blank" rel="noopener">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://github.com/nlaongtup" target="_blank" rel="noopener">
              <i class="fab fa-github-square"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://www.facebook.com/harunaoto13" target="_blank" rel="noopener">
              <i class="fab fa-facebook"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
    

    

    


  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.c457960e56be5ee39cebb84e118b10c1.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
